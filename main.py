from pathlib import Path
import sys
if hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding="utf-8")
import pandas as pd
import numpy as np
from scipy.spatial.distance import euclidean
from fastdtw import fastdtw
from scipy.spatial.transform import Rotation as R
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import warnings
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, PillowWriter
from mocap.visualization import visualize_results as viz_results
from mocap.visualization import animate_3d_segments as viz_animate
from mocap.visualization import export_joint_map_figure as viz_export_joint_map

warnings.filterwarnings('ignore')


class MocapMotionAnalyzer:
    """
    ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë³µì‹± ë™ì‘ì˜ ìœ ì‚¬ë„ë¥¼ ì •êµí•˜ê²Œ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤.

    v2.14 (ì•ˆì •í™”/ì •í™•ë„ ê°•í™”)
    - CSV ë¡œë“œ ì‹œ ë¹„ìˆ˜ì¹˜â†’NaNâ†’0 ì¹˜í™˜
    - ì¿¼í„°ë‹ˆì–¸ ì´ì¤‘ ì•ˆì „ë§(ì •ê·œí™”/zero-norm êµì •/ë¶€í˜¸ ì—°ì†ì„± ìœ ì§€)
    - ì¢Œí‘œê³„ ì •ë ¬ ì‹œ í”„ë ˆì„ë³„ quaternion ë³´ì • + ìœ„ì¹˜/íšŒì „ ëª¨ë‘ ì•ˆì „ ì²˜ë¦¬
    - ì†ë„/ê°€ì†ë„ ê³„ì‚° ì‹œ ê¸¸ì´/ìœ íš¨ê°’ ë³´ì¥
    - ì„¸ê·¸ë¨¼íŠ¸ ê²€ì¶œ: ë¹ˆ/ì§§ì€ êµ¬ê°„ robust, (start, end) inclusive ë°˜í™˜
    - ìŠ¤ì¼€ì¼ë§: 'standard' | 'minmax' | None (ê³µí†µ fit)
    - DTW: ì…ë ¥ ì „ì²˜ë¦¬(NaN/Infâ†’0), 1D/ND ìë™, quaternion sign-invariant distance
    - ë””ë²„ê·¸ ë¡œê·¸: NaN/Inf/zero-norm/ê¸¸ì´ ë¶ˆì¼ì¹˜ ë“± ì¦‰ì‹œ ë¦¬í¬íŠ¸
    """

    def __init__(self, scaling: str = 'standard', feature_weights: dict | None = None,
                 normalize_scale: bool = True, scale_mode: str = 'combined'):
        assert scaling in ('standard', 'minmax', None)
        self.scaling = scaling

        default_weights = {
            'position': 0.20,
            'rotation': 0.25,
            'velocity': 0.25,
            'acceleration': 0.10,
            'joint_angles': 0.20
        }
        allowed_keys = set(default_weights.keys())
        if feature_weights is not None:
            filtered = {k: float(v) for k, v in feature_weights.items() if k in allowed_keys}
            self.feature_weights = {**default_weights, **filtered}
        else:
            self.feature_weights = default_weights
        s = sum(self.feature_weights.values())
        if s <= 0:
            self.feature_weights = {k: 1.0 for k in self.feature_weights}
            s = sum(self.feature_weights.values())
        self.feature_weights = {k: v / s for k, v in self.feature_weights.items()}

        # ê°ë„ í‚¤(ëˆ„ë½ë˜ë©´ zeroë¡œ ì±„ì›€)
        self.angle_keys = [
            'torso_twist',
            'l_shoulder_angle', 'l_elbow_angle',
            'r_shoulder_angle', 'r_elbow_angle',
            'l_knee_angle', 'r_knee_angle',
            'l_ankle_angle', 'r_ankle_angle',
            'neck_flexion',
        ]

        # ìŠ¤ì¼ˆë ˆí†¤ ìŠ¤ì¼€ì¼ ì •ê·œí™” ì„¤ì •
        assert scale_mode in ('shoulder', 'torso', 'combined')
        self.normalize_scale = bool(normalize_scale)
        self.scale_mode = scale_mode

    def set_feature_weights(self, feature_weights: dict, normalize: bool = True):
        """íŠ¹ì„± ê°€ì¤‘ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."""
        allowed = {'position', 'rotation', 'velocity', 'acceleration', 'joint_angles'}
        if not feature_weights:
            return
        clean = {k: float(v) for k, v in feature_weights.items() if k in allowed}
        self.feature_weights.update(clean)
        if normalize:
            s = sum(self.feature_weights.values())
            if s <= 0:
                self.feature_weights = {k: 1.0 for k in self.feature_weights}
                s = sum(self.feature_weights.values())
            self.feature_weights = {k: v / s for k, v in self.feature_weights.items()}

    # ============================== I/O ==============================

    def load_mocap_data(self, file_path: str) -> pd.DataFrame | None:
        """ëª¨ì…˜ìº¡ì²˜ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ë¹„ìˆ˜ì¹˜ â†’ NaN â†’ 0 ì²˜ë¦¬."""
        try:
            df = pd.read_csv(file_path)
            # ê³µë°± ì»¬ëŸ¼ëª… ì •ë¦¬
            df = df.rename(columns=str.strip)
            # ì „ë¶€ floatë¡œ ì‹œë„, ì‹¤íŒ¨ê°’ì€ NaN
            df = df.apply(pd.to_numeric, errors='coerce')
            # NaNì€ 0ìœ¼ë¡œ ì¹˜í™˜
            n_nans = int(df.isna().sum().sum())
            if n_nans > 0:
                print(f"ê²½ê³ : '{file_path}' ë‚´ ë¹„ìˆ˜ì¹˜ ë˜ëŠ” ê²°ì¸¡ê°’ {n_nans}ê°œë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
            df = df.fillna(0.0)
            print(f"íŒŒì¼ ë¡œë“œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. í”„ë ˆì„ ìˆ˜: {df.shape[0]}, ì»¬ëŸ¼ ìˆ˜: {df.shape[1]}")
            return df
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None

    # ======================= Finite/Shape Guards =====================

    def _safe_array(self, x, name="array"):
        """NaN/Inf â†’ 0 ì¹˜í™˜ + ê²½ê³ ."""
        arr = np.asarray(x, dtype=float)
        if np.any(~np.isfinite(arr)):
            n_bad = int(np.size(arr) - np.isfinite(arr).sum())
            print(f"ê²½ê³ : {name}ì— NaN ë˜ëŠ” Inf ê°’ {n_bad}ê°œë¥¼ 0ìœ¼ë¡œ ì¹˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)
        return arr

    def _ensure_2d(self, x):
        """DTW ì…ë ¥ìš©: 1D â†’ (T,1)ë¡œ ë³€í™˜, ê·¸ ì™¸ëŠ” ì›í˜• ìœ ì§€."""
        x = np.asarray(x, dtype=float)
        if x.ndim == 1:
            return x.reshape(-1, 1)
        return x

    # ======================= Quaternion Utilities ====================

    def _clean_quaternions(self, quats, joint_name="Unknown"):
        """
        ì˜ëª»ëœ ì¿¼í„°ë‹ˆì–¸(0-ë…¸ë¦„/NaN/Inf) â†’ ë‹¨ìœ„ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ëŒ€ì²´,
        ì •ê·œí™” + í”„ë ˆì„ ê°„ ë¶€í˜¸ ì—°ì†ì„± ìœ ì§€.
        ì…ë ¥/ì¶œë ¥: (T, 4) [x, y, z, w]
        """
        if quats is None or len(quats) == 0:
            return quats

        q = self._safe_array(quats, name=f"{joint_name}.rotation").astype(float)

        # 1) zero-norm â†’ ë‹¨ìœ„ì¿¼í„°ë‹ˆì–¸ ëŒ€ì²´
        norms = np.linalg.norm(q, axis=1)
        zero_idx = np.where(norms < 1e-8)[0]
        if len(zero_idx) > 0:
            print(f"ê²½ê³ : '{joint_name}' ì¿¼í„°ë‹ˆì–¸ zero-norm {len(zero_idx)}ê°œë¥¼ [0,0,0,1]ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
            q[zero_idx] = np.array([0, 0, 0, 1], dtype=float)

        # 2) ì •ê·œí™”
        norms = np.linalg.norm(q, axis=1, keepdims=True)
        q = q / np.clip(norms, 1e-8, None)

        # 3) ë¶€í˜¸ ì—°ì†ì„± (í”„ë ˆì„ ê°„ dot < 0 â†’ ë¶€í˜¸ ë°˜ì „)
        for i in range(1, len(q)):
            if float(np.dot(q[i - 1], q[i])) < 0.0:
                q[i] = -q[i]

        return q

    def _normalize_quat_sequence(self, quats, name="quat_seq"):
        """ì •ê·œí™”ë§Œ ìˆ˜í–‰(ë¶€í˜¸ì—°ì†ì„±ì€ ì™¸ë¶€ì—ì„œ ìˆ˜í–‰)."""
        if quats is None or len(quats) == 0:
            return quats
        q = self._safe_array(quats, name=name)
        norms = np.linalg.norm(q, axis=1, keepdims=True)
        q = q / np.clip(norms, 1e-8, None)
        return q

    # ===================== Coordinate Alignment =====================

    def _align_coordinate_system(self, features):
        """
        ì‹œì‘ ë°©í–¥ì´ ë‹¬ë¼ë„ ë™ì¼í•œ ì¡°ê±´ì—ì„œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ì¢Œí‘œê³„ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤.
        - Hip/Chest í•„ìš”
        - ìœ„ì¹˜ëŠ” ì¼ê´„ íšŒì „
        - íšŒì „ì€ í”„ë ˆì„ë³„ë¡œ align_rotationê³¼ í•©ì„±
        """
        if 'Hip' not in features or 'Chest' not in features:
            return features

        hip_pos_initial = features['Hip'].get('position')
        chest_pos_initial = features['Chest'].get('position')
        if hip_pos_initial is None or chest_pos_initial is None:
            return features

        hip0 = np.asarray(hip_pos_initial[0], dtype=float)
        chest0 = np.asarray(chest_pos_initial[0], dtype=float)
        forward_vec = chest0 - hip0
        # ìˆ˜í‰ë©´ íˆ¬ì˜
        if len(forward_vec) >= 2:
            forward_vec[1] = 0.0

        norm = np.linalg.norm(forward_vec)
        if norm < 1e-6:
            # ì •ë ¬ ë¶ˆê°€ â†’ ì›ë³¸ ìœ ì§€
            return features
        forward_vec = forward_vec / norm

        target_vec = np.array([0.0, 0.0, 1.0], dtype=float)
        # íšŒì „ì¶•/ê°
        rotation_axis = np.cross(forward_vec, target_vec)
        axis_norm = np.linalg.norm(rotation_axis)
        if axis_norm < 1e-8:
            align_rotation = R.identity()
        else:
            rotation_axis = rotation_axis / axis_norm
            cosang = float(np.clip(np.dot(forward_vec, target_vec), -1.0, 1.0))
            rotation_angle = float(np.arccos(cosang))
            align_rotation = R.from_rotvec(rotation_angle * rotation_axis)

        # ì ìš©
        for joint, jfeat in features.items():
            # ìœ„ì¹˜
            if 'position' in jfeat and jfeat['position'] is not None:
                pos = self._safe_array(jfeat['position'], name=f"{joint}.position")
                try:
                    jfeat['position'] = self._safe_array(
                        align_rotation.apply(pos),
                        name=f"{joint}.position_aligned"
                    )
                except Exception:
                    # shape ë¶ˆì¼ì¹˜ ë“± ì˜ˆì™¸ ë°œìƒ ì‹œ ì›ë³¸ ìœ ì§€
                    jfeat['position'] = pos

            # íšŒì „ (í”„ë ˆì„ë³„ í•©ì„±)
            if 'rotation' in jfeat and jfeat['rotation'] is not None:
                quats = self._clean_quaternions(jfeat['rotation'], joint_name=joint)
                fixed_quats = []
                for t in range(len(quats)):
                    q = quats[t]
                    if np.linalg.norm(q) < 1e-8:
                        q = np.array([0, 0, 0, 1], dtype=float)
                    try:
                        r = R.from_quat(q)
                        aligned_q = (align_rotation * r).as_quat()
                    except Exception:
                        aligned_q = np.array([0, 0, 0, 1], dtype=float)
                    fixed_quats.append(aligned_q)
                jfeat['rotation'] = self._safe_array(np.array(fixed_quats), name=f"{joint}.rotation_aligned")

        return features

    # =================== Skeleton Scale Normalization ===================

    def _estimate_body_scale(self, positions: dict[str, np.ndarray], mode: str = 'combined') -> float:
        """í”„ë ˆì„ ì „ë°˜ì˜ ëŒ€í‘œ ìŠ¤ì¼€ì¼ì„ ì¶”ì •í•©ë‹ˆë‹¤. ë°˜í™˜ê°’ì´ 0ì´ë©´ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        mode:
          - 'shoulder': LShoulderâ€“RShoulder ê±°ë¦¬ì˜ ì¤‘ì•™ê°’
          - 'torso': Hipâ€“Chest ê±°ë¦¬ì˜ ì¤‘ì•™ê°’
          - 'combined': ì‚¬ìš© ê°€ëŠ¥í•œ í•­ëª©ì˜ ê¸°í•˜í‰ê· 
        """
        def median_dist(a: str, b: str) -> float | None:
            if a in positions and b in positions and positions[a] is not None and positions[b] is not None:
                pa = np.asarray(positions[a], dtype=float)
                pb = np.asarray(positions[b], dtype=float)
                T = min(len(pa), len(pb))
                if T == 0:
                    return None
                d = np.linalg.norm(pb[:T] - pa[:T], axis=1)
                if d.size == 0:
                    return None
                med = float(np.median(d))
                return med if np.isfinite(med) and med > 1e-8 else None
            return None

        shoulder = median_dist('LShoulder', 'RShoulder')
        torso = median_dist('Hip', 'Chest')

        if mode == 'shoulder':
            return shoulder or 0.0
        if mode == 'torso':
            return torso or 0.0

        vals = [v for v in (shoulder, torso) if v is not None and v > 0]
        if not vals:
            return 0.0
        if len(vals) == 1:
            return vals[0]
        # ê¸°í•˜í‰ê· ì´ ìŠ¤ì¼€ì¼ ì¶”ì •ì— ì•ˆì •ì 
        logv = np.log(vals)
        return float(np.exp(np.mean(logv)))

    def _apply_scale_normalization(self, raw: dict, mode: str = 'combined') -> dict:
        """ìŠ¤ì¼ˆë ˆí†¤ ìœ„ì¹˜(ë° íŒŒìƒ ì†ì„±ì— ì•ì„œ)ë¥¼ ìŠ¤ì¼€ì¼ë¡œ ë‚˜ëˆ  ì •ê·œí™”í•©ë‹ˆë‹¤."""
        positions = {j: d.get('position') for j, d in raw.items() if 'position' in d}
        scale = self._estimate_body_scale(positions, mode=mode)
        if scale <= 0.0:
            return raw
        for j, d in raw.items():
            if 'position' in d and d['position'] is not None:
                d['position'] = self._safe_array(d['position'] / scale, name=f"{j}.pos_scaled")
        return raw

    def _rescale_target_to_reference(self, f_ref: dict, f_tgt: dict, mode: str = 'combined') -> tuple[dict, float]:
        """motion2(íƒ€ê¹ƒ)ì˜ ìœ„ì¹˜ë¥¼ motion1(ë ˆí¼ëŸ°ìŠ¤)ì˜ ì²´í˜• ìŠ¤ì¼€ì¼ì— ë§ì¶¥ë‹ˆë‹¤.

        ë°˜í™˜: (ìŠ¤ì¼€ì¼ ì ìš©ëœ position ë”•ì…”ë„ˆë¦¬, ì ìš© ë°°ìœ¨ factor)
        """
        pos_ref = f_ref.get('position', {})
        pos_tgt = f_tgt.get('position', {})
        ref_positions = {j: arr for j, arr in pos_ref.items() if arr is not None}
        tgt_positions = {j: arr for j, arr in pos_tgt.items() if arr is not None}
        s_ref = self._estimate_body_scale(ref_positions, mode=mode)
        s_tgt = self._estimate_body_scale(tgt_positions, mode=mode)
        if s_ref <= 0.0 or s_tgt <= 0.0:
            return pos_tgt, 1.0
        factor = float(s_ref / s_tgt)
        scaled = {}
        for j, arr in pos_tgt.items():
            if arr is None:
                continue
            scaled[j] = self._safe_array(arr * factor, name=f"{j}.pos_refscaled")
        return scaled, factor

    def _compute_forward_from_features(self, f: dict) -> np.ndarray | None:
        pos = f.get('position', {})
        if 'Hip' not in pos or 'Chest' not in pos:
            return None
        hip = np.asarray(pos['Hip'][0], dtype=float)
        chest = np.asarray(pos['Chest'][0], dtype=float)
        v = chest - hip
        if v.shape[0] >= 2:
            v[1] = 0.0
        n = np.linalg.norm(v)
        if n < 1e-8:
            return None
        return v / n

    def _rotation_from_to(self, src: np.ndarray, dst: np.ndarray) -> R:
        src = np.asarray(src, dtype=float)
        dst = np.asarray(dst, dtype=float)
        src = src / (np.linalg.norm(src) + 1e-8)
        dst = dst / (np.linalg.norm(dst) + 1e-8)
        axis = np.cross(src, dst)
        axis_n = np.linalg.norm(axis)
        if axis_n < 1e-8:
            return R.identity()
        axis = axis / axis_n
        cosang = float(np.clip(np.dot(src, dst), -1.0, 1.0))
        angle = float(np.arccos(cosang))
        return R.from_rotvec(angle * axis)

    def _apply_rotation_to_features(self, feats: dict, rot: R):
        # ìœ„ì¹˜/ì†ë„/ê°€ì†ë„ íšŒì „
        for ftype in ('position', 'velocity', 'acceleration'):
            if ftype in feats:
                for j, arr in feats[ftype].items():
                    if arr is None:
                        continue
                    try:
                        feats[ftype][j] = self._safe_array(rot.apply(arr), name=f"{j}.{ftype}_rot")
                    except Exception:
                        feats[ftype][j] = arr
        # íšŒì „(quaternion) í•©ì„±
        if 'rotation' in feats:
            for j, quats in feats['rotation'].items():
                if quats is None:
                    continue
                new_qs = []
                for q in quats:
                    try:
                        r = R.from_quat(q)
                        nq = (rot * r).as_quat()
                    except Exception:
                        nq = q
                    new_qs.append(nq)
                feats['rotation'][j] = self._safe_array(np.array(new_qs), name=f"{j}.rotation_rot")

    def _scale_vel_acc_features(self, feats: dict, factor: float):
        if abs(factor - 1.0) < 1e-12:
            return
        for ftype in ('velocity', 'acceleration'):
            if ftype in feats:
                for j, arr in feats[ftype].items():
                    if arr is None:
                        continue
                    feats[ftype][j] = self._safe_array(arr * factor, name=f"{j}.{ftype}_scaled")

    # =================== Per-Joint Feature Similarities ===================

    def _compute_per_joint_feature_similarities(self, f1: dict, f2: dict,
                                                s1: int, e1: int, s2: int, e2: int) -> dict:
        """ê° íŠ¹ì„±ë³„ë¡œ ì¡°ì¸íŠ¸(ë˜ëŠ” ê°ë„ í‚¤) ë‹¨ìœ„ì˜ DTW ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        ë°˜í™˜ í˜•íƒœ: { feature_type: { key: similarity, ... }, ... }
        - feature_type âˆˆ {'position','rotation','velocity','acceleration','joint_angles'}
        - key: ì¡°ì¸íŠ¸ëª… ë˜ëŠ” ê°ë„ í‚¤ëª…
        """
        result: dict[str, dict[str, float]] = {}
        for f_type in self.feature_weights.keys():
            d1 = f1.get(f_type, {})
            d2 = f2.get(f_type, {})
            per_keys: dict[str, float] = {}

            if f_type == 'joint_angles':
                keys = set(d1.keys()) & set(d2.keys())
                for key in keys:
                    seq1 = d1[key][s1:e1 + 1]
                    seq2 = d2[key][s2:e2 + 1]
                    if seq1.size == 0 or seq2.size == 0:
                        continue
                    per_keys[key] = self._dtw_similarity(seq1, seq2)
            else:
                keys = set(d1.keys()) & set(d2.keys())
                for key in keys:
                    seq1 = d1[key][s1:e1 + 1]
                    seq2 = d2[key][s2:e2 + 1]
                    if seq1.size == 0 or seq2.size == 0:
                        continue
                    if f_type == 'rotation':
                        seq1 = self._normalize_quat_sequence(seq1, name=f"{key}.rot1")
                        seq2 = self._normalize_quat_sequence(seq2, name=f"{key}.rot2")
                        for qarr in (seq1, seq2):
                            for i in range(1, len(qarr)):
                                if float(np.dot(qarr[i - 1], qarr[i])) < 0.0:
                                    qarr[i] = -qarr[i]
                        scaled_seq1, scaled_seq2 = seq1, seq2
                    else:
                        scaled_seq1, scaled_seq2 = (seq1, seq2) if self.scaling is None else self._fit_scaler(seq1, seq2)
                    per_keys[key] = self._dtw_similarity(scaled_seq1, scaled_seq2)

            result[f_type] = per_keys
        return result

    def export_per_joint_similarities(self, per_joint: dict, output_path: str):
        """per_joint ìœ ì‚¬ë„ ê²°ê³¼ë¥¼ ê°„ë‹¨í•œ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        CSV ì»¬ëŸ¼: feature_type,key,similarity
        """
        import csv
        rows = []
        for f_type, mapping in per_joint.items():
            for key, sim in mapping.items():
                rows.append((f_type, key, float(sim)))
        try:
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['feature_type', 'key', 'similarity'])
                writer.writerows(rows)
            print(f"per-joint ìœ ì‚¬ë„ ê²°ê³¼ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {output_path}")
        except Exception as e:
            print(f"per-joint ìœ ì‚¬ë„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # =========================== Features ===========================

    def extract_features(self, df: pd.DataFrame):
        """ì¢…í•©ì ì¸ íŠ¹ì„±ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        print("ì¢…í•© íŠ¹ì„± ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        # joint ëª©ë¡
        joints = sorted(set([c.split('.')[0] for c in df.columns if '.' in c]))

        raw = {}
        for joint in joints:
            pos_cols = [f'{joint}.posX', f'{joint}.posY', f'{joint}.posZ']
            rot_cols = [f'{joint}.rotX', f'{joint}.rotY', f'{joint}.rotZ', f'{joint}.rotW']

            jfeat = {}

            if all(c in df.columns for c in pos_cols):
                pos = df[pos_cols].to_numpy(dtype=float)
                jfeat['position'] = self._safe_array(pos, name=f"{joint}.pos")

            if all(c in df.columns for c in rot_cols):
                raw_quats = df[rot_cols].to_numpy(dtype=float)
                jfeat['rotation'] = self._clean_quaternions(raw_quats, joint_name=joint)

            if jfeat:
                raw[joint] = jfeat

        if 'Hip' not in raw or 'position' not in raw['Hip']:
            raise ValueError("'Hip' ì¡°ì¸íŠ¸ position ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # Hip ê¸°ì¤€ ì¤‘ì‹¬í™”
        hip = raw['Hip']['position'].copy()
        for jfeat in raw.values():
            if 'position' in jfeat:
                jfeat['position'] = self._safe_array(jfeat['position'] - hip, name="centered_pos")

        # ì¢Œí‘œê³„ ì •ë ¬
        raw = self._align_coordinate_system(raw)

        # ìŠ¤ì¼ˆë ˆí†¤ ìŠ¤ì¼€ì¼ ì •ê·œí™”(ì˜µì…˜)
        if self.normalize_scale:
            raw = self._apply_scale_normalization(raw, mode=self.scale_mode)

        # ì†ë„/ê°€ì†ë„ ê³„ì‚°
        for j, jfeat in raw.items():
            if 'position' in jfeat and jfeat['position'] is not None and len(jfeat['position']) > 0:
                pos = self._safe_array(jfeat['position'], name=f"{j}.pos_for_vel")
                vel = np.diff(pos, axis=0, prepend=pos[0:1])
                acc = np.diff(vel, axis=0, prepend=vel[0:1])
                jfeat['velocity'] = self._safe_array(vel, name=f"{j}.vel")
                jfeat['acceleration'] = self._safe_array(acc, name=f"{j}.acc")

        # ë²¡í„°/ê°ë„
        joint_positions = {j: d['position'] for j, d in raw.items() if 'position' in d}
        pairs = [
            ('LShoulder', 'RShoulder'), ('LThigh', 'RThigh'),
            ('Chest', 'Ab'),
            ('LShoulder', 'LUArm'), ('RShoulder', 'RUArm'),
            ('LUArm', 'LFArm'), ('RUArm', 'RFArm'),
            # Legs
            ('LThigh', 'LShin'), ('LShin', 'LFoot'), ('LFoot', 'LToe'),
            ('RThigh', 'RShin'), ('RShin', 'RFoot'), ('RFoot', 'RToe'),
            # Neck/Head
            ('Chest', 'Neck'), ('Neck', 'Head'),
        ]
        vectors = {}
        for a, b in pairs:
            vec = self._calculate_vector(joint_positions, a, b)
            if vec is not None:
                vectors[f"{a}_{b}"] = vec

        T = len(next(iter(joint_positions.values()))) if len(joint_positions) else len(df)

        def safe_angle(vkey1, vkey2):
            if vkey1 in vectors and vkey2 in vectors:
                return self._calculate_angle(vectors[vkey1], vectors[vkey2])
            return np.zeros(T, dtype=float)

        def safe_signed_angle(vkey1, vkey2, normal=(0.0, 1.0, 0.0)):
            if vkey1 in vectors and vkey2 in vectors:
                return self._signed_angle(vectors[vkey1], vectors[vkey2], normal=normal)
            return np.zeros(T, dtype=float)

        joint_angles = {
            # ìˆ˜í‰ë©´(Y ë²•ì„ ) ê¸°ì¤€ìœ¼ë¡œ ì¢Œ/ìš° ë¹„í‹€ë¦¼ ë¶€í˜¸ë¥¼ ê°€ì§„ ê°ë„
            'torso_twist': safe_signed_angle('LShoulder_RShoulder', 'LThigh_RThigh', normal=(0.0, 1.0, 0.0)),
            'l_shoulder_angle': safe_angle('Chest_Ab', 'LShoulder_LUArm'),
            'l_elbow_angle': safe_angle('LShoulder_LUArm', 'LUArm_LFArm'),
            'r_shoulder_angle': safe_angle('Chest_Ab', 'RShoulder_RUArm'),
            'r_elbow_angle': safe_angle('RShoulder_RUArm', 'RUArm_RFArm'),
            # Legs
            'l_knee_angle': safe_angle('LThigh_LShin', 'LShin_LFoot'),
            'r_knee_angle': safe_angle('RThigh_RShin', 'RShin_RFoot'),
            'l_ankle_angle': safe_angle('LShin_LFoot', 'LFoot_LToe'),
            'r_ankle_angle': safe_angle('RShin_RFoot', 'RFoot_RToe'),
            # Head/neck
            'neck_flexion': safe_angle('Chest_Neck', 'Neck_Head'),
        }

        # ìµœì¢… ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        feats = {'position': {}, 'rotation': {}, 'velocity': {}, 'acceleration': {}, 'joint_angles': {}}
        for joint, jfeat in raw.items():
            for ftype in ('position', 'rotation', 'velocity', 'acceleration'):
                if ftype in jfeat and jfeat[ftype] is not None:
                    feats[ftype][joint] = self._safe_array(jfeat[ftype], name=f"{joint}.{ftype}")

        feats['joint_angles'] = {k: self._safe_array(joint_angles.get(k, np.zeros(T)), name=f"angle.{k}") for k in self.angle_keys}

        print("íŠ¹ì„± ì¶”ì¶œì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return feats

    # ======================= Motion Segmentation ====================

    def segment_action(self, features, threshold_ratio=0.15, min_length=30):
        """
        ì†ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘ì˜ í•µì‹¬ êµ¬ê°„ì„ íƒì§€í•©ë‹ˆë‹¤.
        ë°˜í™˜: (start_idx, end_idx)  (end_idx í¬í•¨)
        """
        vlist = [np.linalg.norm(v, axis=1) for v in features['velocity'].values() if v is not None and len(v) > 0]
        if not vlist:
            any_len = len(next(iter(features['position'].values()))) if features['position'] else 0
            return 0, max(any_len - 1, 0)

        total_velocity = np.sum(vlist, axis=0)
        total_velocity = self._safe_array(total_velocity, name="total_velocity")

        if total_velocity.size == 0:
            return 0, 0

        thr = float(np.max(total_velocity)) * float(threshold_ratio)
        active = np.where(total_velocity > thr)[0]

        if active.size < min_length:
            return 0, len(total_velocity) - 1

        start_idx, end_idx = int(active[0]), int(active[-1])
        print(f"ë™ì‘ êµ¬ê°„ì„ íƒì§€í–ˆìŠµë‹ˆë‹¤. ì‹œì‘ í”„ë ˆì„: {start_idx}, ì¢…ë£Œ í”„ë ˆì„: {end_idx}, ì´ ê¸¸ì´: {end_idx - start_idx + 1} í”„ë ˆì„")
        return start_idx, end_idx

    # ============================= Math =============================

    def _calculate_angle(self, v1, v2):
        v1 = self._safe_array(v1, name="angle_v1")
        v2 = self._safe_array(v2, name="angle_v2")
        v1_u = v1 / (np.linalg.norm(v1, axis=1, keepdims=True) + 1e-8)
        v2_u = v2 / (np.linalg.norm(v2, axis=1, keepdims=True) + 1e-8)
        dot = np.einsum('ij,ij->i', v1_u, v2_u)
        dot = np.clip(dot, -1.0, 1.0)
        return np.arccos(dot)

    def _signed_angle(self, v1, v2, normal=(0.0, 1.0, 0.0)):
        """í‰ë©´ ë²•ì„  normalì— ëŒ€í•œ ì„œëª… ê°ë„(ë¼ë””ì•ˆ, -pi~pi).
        v1, v2ëŠ” (T,3). ìˆ˜í‰ë©´(XZ) ì„œëª… ê°ë„ì˜ ê²½ìš° normal=(0,1,0).
        """
        v1 = self._safe_array(v1, name="signed_angle_v1")
        v2 = self._safe_array(v2, name="signed_angle_v2")
        n = np.asarray(normal, dtype=float)
        n = n / (np.linalg.norm(n) + 1e-8)
        # í‰ë©´ íˆ¬ì˜
        v1p = v1 - np.einsum('ij,j->i', v1, n)[:, None] * n[None, :]
        v2p = v2 - np.einsum('ij,j->i', v2, n)[:, None] * n[None, :]
        # ì •ê·œí™”
        v1p = v1p / (np.linalg.norm(v1p, axis=1, keepdims=True) + 1e-8)
        v2p = v2p / (np.linalg.norm(v2p, axis=1, keepdims=True) + 1e-8)
        # dot, cross
        dot = np.einsum('ij,ij->i', v1p, v2p)
        dot = np.clip(dot, -1.0, 1.0)
        cross = np.cross(v1p, v2p)
        s = np.einsum('ij,j->i', cross, n)
        return np.arctan2(s, dot)

    def _calculate_vector(self, positions, start_joint, end_joint):
        if start_joint in positions and end_joint in positions:
            a = positions[start_joint]
            b = positions[end_joint]
            if a is None or b is None or len(a) == 0 or len(b) == 0:
                return None
            T = min(len(a), len(b))
            a = np.asarray(a[:T], dtype=float)
            b = np.asarray(b[:T], dtype=float)
            return self._safe_array(b - a, name=f"vec.{start_joint}_{end_joint}")
        return None

    # ======================= Scaling & DTW ==========================

    def _fit_scaler(self, seq1, seq2):
        """ì„ íƒëœ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë‘ ì‹œí€€ìŠ¤ì— ê³µí†µìœ¼ë¡œ í”¼íŒ…/ì ìš©."""
        if self.scaling is None:
            return seq1, seq2

        _s1 = self._ensure_2d(seq1)
        _s2 = self._ensure_2d(seq2)
        if _s1.shape[1] != _s2.shape[1]:
            return seq1, seq2  # ì°¨ì› ë¶ˆì¼ì¹˜ ì‹œ ìŠ¤í‚µ

        if self.scaling == 'standard':
            scaler = StandardScaler()
        else:
            scaler = MinMaxScaler()

        both = np.vstack([_s1, _s2])
        both = self._safe_array(both, name="scaler_fit_input")
        scaler.fit(both)

        s1 = scaler.transform(_s1)
        s2 = scaler.transform(_s2)
        # ì›ë˜ ì°¨ì› ìœ ì§€(1Dì˜€ë‹¤ë©´ ë‹¤ì‹œ 1Dë¡œ)
        if seq1.ndim == 1: s1 = s1.flatten()
        if seq2.ndim == 1: s2 = s2.flatten()
        return s1, s2

    def _dtw_similarity(self, seq1, seq2, k=10):
        """DTW ê±°ë¦¬ë¥¼ ì •ê·œí™”í•˜ê³  ì§€ìˆ˜ í•¨ìˆ˜ë¡œ ìœ ì‚¬ë„ë¡œ ë³€í™˜."""
        if not isinstance(seq1, np.ndarray): seq1 = np.array(seq1, dtype=float)
        if not isinstance(seq2, np.ndarray): seq2 = np.array(seq2, dtype=float)
        if seq1.size == 0 or seq2.size == 0: return 0.0

        # ìµœì¢… ì•ˆì „í™”
        seq1 = self._safe_array(seq1, name="dtw_seq1")
        seq2 = self._safe_array(seq2, name="dtw_seq2")

        # ê±°ë¦¬ í•¨ìˆ˜ ì„ íƒ
        if seq1.ndim == 1:
            dist_func = lambda x, y: float(abs(x - y))
        elif seq1.shape[1] == 4:
            # ì¿¼í„°ë‹ˆì–¸ sign-invariant
            def quat_dist(q1, q2):
                d = float(abs(np.dot(q1, q2)))
                d = np.clip(d, -1.0, 1.0)
                return 1.0 - d
            dist_func = quat_dist
        else:
            dist_func = euclidean

        distance, _ = fastdtw(seq1, seq2, dist=dist_func)
        normalized_distance = distance / (len(seq1) + len(seq2))
        return float(np.exp(-k * normalized_distance))

    # ============================ Compare ===========================

    def compare_motions(self, motion1_data: pd.DataFrame, motion2_data: pd.DataFrame):
        """ë‘ ë™ì‘ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤."""
        print("\në‘ ë™ì‘ì˜ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        try:
            f1 = self.extract_features(motion1_data)
            f2 = self.extract_features(motion2_data)

            # 1) motion1 ê¸°ì¤€ìœ¼ë¡œ motion2ì˜ ì²´í˜• ìŠ¤ì¼€ì¼ì„ ì¼ì¹˜
            if 'position' in f1 and 'position' in f2:
                rescaled_pos2, factor = self._rescale_target_to_reference(f1, f2, mode=self.scale_mode)
                if rescaled_pos2:
                    f2['position'].update(rescaled_pos2)
                    # ì†ë„/ê°€ì†ë„ë„ ë™ì¼ ë°°ìœ¨ ë°˜ì˜(ìœ„ì¹˜ ì°¨ë¶„ ê¸°ë°˜ì´ë¯€ë¡œ ë™ì¼ ìŠ¤ì¼€ì¼ í•„ìš”)
                    self._scale_vel_acc_features(f2, factor)

            # 2) motion1ì˜ ì „ë°©ì„ ê¸°ì¤€ìœ¼ë¡œ motion2 ë°©í–¥ì„ ì¼ì¹˜(ì¢Œí‘œê³„ íšŒì „)
            fwd1 = self._compute_forward_from_features(f1)
            fwd2 = self._compute_forward_from_features(f2)
            if fwd1 is not None and fwd2 is not None:
                rot = self._rotation_from_to(fwd2, fwd1)  # motion2 -> motion1 ë°©í–¥ìœ¼ë¡œ íšŒì „
                self._apply_rotation_to_features(f2, rot)

            s1, e1 = self.segment_action(f1)
            s2, e2 = self.segment_action(f2)

            feature_similarities = {}

            for f_type in self.feature_weights.keys():
                print(f"íŠ¹ì„± '{f_type}' ìœ ì‚¬ë„ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
                sims = []

                d1 = f1[f_type]
                d2 = f2[f_type]

                if f_type == 'joint_angles':
                    keys = set(d1.keys()) & set(d2.keys())
                    for key in keys:
                        seq1 = d1[key][s1:e1 + 1]
                        seq2 = d2[key][s2:e2 + 1]
                        if seq1.size == 0 or seq2.size == 0:
                            continue
                        # ê°ë„ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”
                        sim = self._dtw_similarity(seq1, seq2)
                        sims.append(sim)
                else:
                    keys = set(d1.keys()) & set(d2.keys())
                    for key in keys:
                        seq1 = d1[key][s1:e1 + 1]
                        seq2 = d2[key][s2:e2 + 1]
                        if seq1.size == 0 or seq2.size == 0:
                            continue

                        if f_type == 'rotation':
                            # ì •ê·œí™” + ë¶€í˜¸ì—°ì†ì„±
                            seq1 = self._normalize_quat_sequence(seq1, name=f"{key}.rot1")
                            seq2 = self._normalize_quat_sequence(seq2, name=f"{key}.rot2")
                            for qarr in (seq1, seq2):
                                for i in range(1, len(qarr)):
                                    if float(np.dot(qarr[i - 1], qarr[i])) < 0.0:
                                        qarr[i] = -qarr[i]
                            scaled_seq1, scaled_seq2 = seq1, seq2
                        else:
                            # ìœ„ì¹˜/ì†ë„/ê°€ì†ë„
                            scaled_seq1, scaled_seq2 = (seq1, seq2) if self.scaling is None else self._fit_scaler(seq1, seq2)

                        sim = self._dtw_similarity(scaled_seq1, scaled_seq2)
                        sims.append(sim)

                feature_similarities[f_type] = float(np.mean(sims)) if sims else 0.0

            # íŒŒíŠ¸(ì™¼íŒ”/ì˜¤ë¥¸íŒ”/ì™¼ë‹¤ë¦¬/ì˜¤ë¥¸ë‹¤ë¦¬/ì½”ì–´/ë¨¸ë¦¬) ë‹¨ìœ„ DTW ì‚°ì¶œ
            parts = {
                'left_arm': ['LShoulder', 'LUArm', 'LFArm', 'LHand'],
                'right_arm': ['RShoulder', 'RUArm', 'RFArm', 'RHand'],
                'left_leg': ['LThigh', 'LShin', 'LFoot', 'LToe'],
                'right_leg': ['RThigh', 'RShin', 'RFoot', 'RToe'],
                'core': ['LThigh', 'RThigh', 'Hip', 'Ab', 'Chest'],
                'head': ['LShoulder', 'RShoulder', 'Neck', 'Head'],
            }

            # íŒŒíŠ¸ë³„ ê°ë„ í‚¤ ë§¤í•‘(í•´ë‹¹ íŒŒíŠ¸ì— ì˜ë¯¸ ìˆëŠ” ê°ë„ë§Œ ì‚¬ìš©)
            angle_keys_by_part: dict[str, set[str]] = {
                'left_arm': {'l_shoulder_angle', 'l_elbow_angle'},
                'right_arm': {'r_shoulder_angle', 'r_elbow_angle'},
                'left_leg': {'l_knee_angle', 'l_ankle_angle'},
                'right_leg': {'r_knee_angle', 'r_ankle_angle'},
                'core': {'torso_twist'},
                'head': {'neck_flexion'},
            }

            part_scores = {}
            part_breakdown = {}
            # í”¼ì²˜ë³„ íŒŒíŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚° í•¨ìˆ˜
            def part_feature_score(feature_type: str, joints_set: set[str], part_name: str) -> float:
                d1 = f1.get(feature_type, {})
                d2 = f2.get(feature_type, {})
                sims_local = []
                if feature_type == 'joint_angles':
                    # íŒŒíŠ¸ì— í•´ë‹¹í•˜ëŠ” ê°ë„ í‚¤ë§Œ ì‚¬ìš©
                    allowed = angle_keys_by_part.get(part_name, set())
                    keys = (set(d1.keys()) & set(d2.keys())) & allowed
                    for key in keys:
                        seq1 = d1[key][s1:e1 + 1]
                        seq2 = d2[key][s2:e2 + 1]
                        if seq1.size == 0 or seq2.size == 0:
                            continue
                        sims_local.append(self._dtw_similarity(seq1, seq2))
                else:
                    keys = (set(d1.keys()) & set(d2.keys())) & joints_set
                    for key in keys:
                        seq1 = d1[key][s1:e1 + 1]
                        seq2 = d2[key][s2:e2 + 1]
                        if seq1.size == 0 or seq2.size == 0:
                            continue
                        if feature_type == 'rotation':
                            seq1 = self._normalize_quat_sequence(seq1, name=f"{key}.rot1")
                            seq2 = self._normalize_quat_sequence(seq2, name=f"{key}.rot2")
                            for qarr in (seq1, seq2):
                                for i in range(1, len(qarr)):
                                    if float(np.dot(qarr[i - 1], qarr[i])) < 0.0:
                                        qarr[i] = -qarr[i]
                            scaled_seq1, scaled_seq2 = seq1, seq2
                        else:
                            scaled_seq1, scaled_seq2 = (seq1, seq2) if self.scaling is None else self._fit_scaler(seq1, seq2)
                        sims_local.append(self._dtw_similarity(scaled_seq1, scaled_seq2))
                return float(np.mean(sims_local)) if sims_local else 0.0

            for part_name, part_joints in parts.items():
                jset = set(part_joints)
                # ëª¨ë“  í”¼ì²˜ë¥¼ ê³ ë ¤í•œ íŒŒíŠ¸ ìŠ¤ì½”ì–´(ë™ì¼ ê°€ì¤‘ í‰ê· )
                per_feature_scores = {}
                for f_type in ('position', 'rotation', 'velocity', 'acceleration', 'joint_angles'):
                    per_feature_scores[f_type] = part_feature_score(f_type, jset, part_name)
                part_breakdown[part_name] = per_feature_scores
                vals = list(per_feature_scores.values())
                part_scores[part_name] = float(np.mean(vals)) if vals else 0.0

            # ì¡°ì¸íŠ¸ ë‹¨ìœ„ ìœ ì‚¬ë„(ì „ íŠ¹ì„±) ì‚°ì¶œ ë° ë‚´ë³´ë‚´ê¸° ìš©ë„ë¡œ í•¨ê»˜ ë°˜í™˜
            per_joint = self._compute_per_joint_feature_similarities(f1, f2, s1, e1, s2, e2)

            # ê°€ì¤‘ í•© (ì „ì²´)
            final_similarity = 0.0
            for f_type, sim in feature_similarities.items():
                final_similarity += sim * self.feature_weights.get(f_type, 0.0)

            return float(final_similarity), {
                **feature_similarities,
                **{f"part_{k}": v for k, v in part_scores.items()},
                'per_joint': per_joint,
                'part_breakdown': part_breakdown,
            }

        except Exception as e:
            import traceback
            print(f"ë™ì‘ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            traceback.print_exc()
            return 0.0, {}

    # =========================== Visualization ======================

    def visualize_results(self, similarity, feature_similarities):
        viz_results(similarity, feature_similarities, self.feature_weights)

    def animate_3d_segments(self, motion1_data: pd.DataFrame, motion2_data: pd.DataFrame,
                            overlay: bool = True, interval: int = 40,
                            save_path: str | None = None,
                            joints_to_show: list[str] | None = None,
                            skeleton_edges: list[tuple[str, str]] | None = None):
        viz_animate(self, motion1_data, motion2_data, overlay, interval, save_path, joints_to_show, skeleton_edges)

    def export_joint_map_figure(self, output_path: str, dpi: int = 200, language: str = 'ko'):
        viz_export_joint_map(output_path, dpi, language)


# ìœ ì‚¬ë„ë¥¼ í•œë²ˆì— ì—¬ëŸ¬ íŒŒì¼ê³¼ ë¹„êµí•˜ëŠ” ë°°ì¹˜ í•¨ìˆ˜

def print_similarity_batch(file1_path: str, file2_dir: str, analyzer: MocapMotionAnalyzer,
                           keyword: str | None = None, limit: int | None = None):
    """
    file2_dir ì•ˆì˜ ëª¨ë“  CSV(ì„ íƒì ìœ¼ë¡œ keyword í•„í„°)ë¥¼ file1ê³¼ ë¹„êµí•˜ê³ ,
    ì „ì²´ ìœ ì‚¬ë„ì™€ ì£¼ìš” í•­ëª©ì„ ì½˜ì†”ì— ê¹”ë”í•˜ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    file1 = Path(file1_path)
    dir2 = Path(file2_dir)

    if not file1.exists():
        print(f"[ì˜¤ë¥˜] file1ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file1}")
        return
    if not dir2.exists() or not dir2.is_dir():
        print(f"[ì˜¤ë¥˜] file2 ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dir2}")
        return

    # file1ì€ í•œ ë²ˆë§Œ ë¡œë“œ
    motion1 = analyzer.load_mocap_data(str(file1))
    if motion1 is None:
        print("[ì˜¤ë¥˜] file1 ë¡œë“œ ì‹¤íŒ¨ë¡œ ë°°ì¹˜ ë¹„êµë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ëŒ€ìƒ íŒŒì¼ ìˆ˜ì§‘
    candidates = sorted([p for p in dir2.glob("*.csv") if p.is_file()])
    if keyword:
        candidates = [p for p in candidates if keyword.lower() in p.name.lower()]
    # file1ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ë„ ì œì™¸
    candidates = [p for p in candidates if p.resolve() != file1.resolve()]
    if limit is not None:
        candidates = candidates[:limit]

    if not candidates:
        msg = f"'{dir2}'ì—ì„œ ë¹„êµí•  CSVê°€ ì—†ìŠµë‹ˆë‹¤."
        if keyword:
            msg += f" (í‚¤ì›Œë“œ='{keyword}')"
        print(msg)
        return

    print("\n" + "=" * 72)
    print(f"[ë°°ì¹˜ ë¹„êµ ì‹œì‘] ê¸°ì¤€ íŒŒì¼: {file1.name}  |  ëŒ€ìƒ ë””ë ‰í„°ë¦¬: {dir2}")
    if keyword:
        print(f"í‚¤ì›Œë“œ í•„í„°: {keyword}")
    print(f"ì´ ëŒ€ìƒ íŒŒì¼ ìˆ˜: {len(candidates)}")
    print("=" * 72)

    for idx, p in enumerate(candidates, start=1):
        print(f"\n[{idx}/{len(candidates)}] ë¹„êµ ëŒ€ìƒ: {p.name}")
        motion2 = analyzer.load_mocap_data(str(p))
        if motion2 is None:
            print(" â†’ ë¡œë“œ ì‹¤íŒ¨, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # ë¹„êµ
        similarity, details = analyzer.compare_motions(motion1, motion2)

        # ì¶œë ¥(ê°„ë‹¨/ëª…ë£Œ)
        print(f" â†’ ì „ì²´ ìœ ì‚¬ë„: {similarity:.4f}")
        # ì£¼ìš” í”¼ì²˜ë³„ ìœ ì‚¬ë„ë§Œ ê³¨ë¼ ê°„ë‹¨ í‘œê¸°
        for key in ('rotation', 'joint_angles', 'position', 'velocity', 'acceleration'):
            if key in details:
                print(f"    - {key:13s}: {details[key]:.4f}")
        # íŒŒíŠ¸ ìš”ì•½(ì›í•˜ë©´ ì£¼ì„ í•´ì œ)
        for part in ('part_left_arm','part_right_arm','part_left_leg','part_right_leg','part_core','part_head'):
            if part in details:
                print(f"    - {part:13s}: {details[part]:.4f}")

    print("\n" + "=" * 72)
    print("[ë°°ì¹˜ ë¹„êµ ì™„ë£Œ]")
    print("=" * 72)
    
    # utils/save_similarity_matrix.py  (ìƒˆ íŒŒì¼ë¡œ ë‘ê±°ë‚˜, ê¸°ì¡´ íŒŒì¼ í•˜ë‹¨ì— ì¶”ê°€í•´ë„ ë©ë‹ˆë‹¤)

import csv
from pathlib import Path

# === ìƒˆ í•¨ìˆ˜: ë°°ì¹˜ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ ===
def save_similarity_matrix(
    file1_path: str,
    file2_dir: str,
    analyzer: MocapMotionAnalyzer,
    keyword: str | None = None,
    limit: int | None = None,
    title: str = "Uppercut(L)",
    output_csv_path: str = "C:\\Users\\harry\\OneDrive\\Desktop\\DTW_Method\\Collaborate_Code\\similarity_matrix.csv"
) -> pd.DataFrame:
    """
    file2_dirì˜ ëª¨ë“  CSV(ì„ íƒì ìœ¼ë¡œ keyword í•„í„°)ë¥¼ file1ê³¼ ë¹„êµí•´
    'ë¶€ìœ„ë³„+í”¼ì²˜ë³„ ìœ ì‚¬ë„'ë¥¼ í•œ ë²ˆì— CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    ì—´ ìˆœì„œ(ê³ ì •):
    Head, Core, Right_Leg, Left_Leg, Right_Arm, Left_Arm,
    Acceleration, Velocity, Position, Joint Angle, rotation
    """
    # ê³ ì • ì—´ ì´ë¦„(ì´ë¯¸ì§€ ìˆœì„œ ê·¸ëŒ€ë¡œ)
    col_order = [
        "Head", "Core", "Right_Leg", "Left_Leg", "Right_Arm", "Left_Arm",
        "Acceleration", "Velocity", "Position", "Joint Angle", "rotation", "Overall"
    ]

    # ë‚´ë¶€ í‚¤ ë§¤í•‘( compare_motions details â†’ í‘œì˜ ì—´ )
    key_map = {
        "Head":         "part_head",
        "Core":         "part_core",
        "Right_Leg":    "part_right_leg",
        "Left_Leg":     "part_left_leg",
        "Right_Arm":    "part_right_arm",
        "Left_Arm":     "part_left_arm",
        "Acceleration": "acceleration",
        "Velocity":     "velocity",
        "Position":     "position",
        "Joint Angle":  "joint_angles",
        "rotation":     "rotation",
    }

    file1 = Path(file1_path)
    dir2  = Path(file2_dir)

    if not file1.exists():
        print(f"[ì˜¤ë¥˜] ê¸°ì¤€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file1}")
        return pd.DataFrame()

    if not dir2.exists() or not dir2.is_dir():
        print(f"[ì˜¤ë¥˜] ëŒ€ìƒ ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {dir2}")
        return pd.DataFrame()

    # ê¸°ì¤€ ëª¨ì…˜ 1íšŒ ë¡œë“œ
    motion1 = analyzer.load_mocap_data(str(file1))
    if motion1 is None:
        print("[ì˜¤ë¥˜] ê¸°ì¤€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
        return pd.DataFrame()

    # í›„ë³´ ìˆ˜ì§‘
    candidates = sorted([p for p in dir2.glob("*.csv") if p.is_file()])
    if keyword:
        candidates = [p for p in candidates if keyword.lower() in p.name.lower()]
    candidates = [p for p in candidates if p.resolve() != file1.resolve()]
    if limit is not None:
        candidates = candidates[:limit]

    if not candidates:
        print(f"[ì•ˆë‚´] ë¹„êµí•  CSVê°€ ì—†ìŠµë‹ˆë‹¤. dir={dir2}, keyword={keyword}")
        return pd.DataFrame()

    # ê²°ê³¼ ëˆ„ì 
    rows = []
    index_labels = []

    for idx, p in enumerate(candidates, start=1):
        print(f"[{idx}/{len(candidates)}] ë¹„êµ: {p.name}")  # ì¡´ëŒ“ë§ ë¡œê·¸
        motion2 = analyzer.load_mocap_data(str(p))
        if motion2 is None:
            print(" â†’ ë¡œë“œ ì‹¤íŒ¨, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        similarity, details = analyzer.compare_motions(motion1, motion2)

        # í•œ í–‰ êµ¬ì„±(ì—†ìœ¼ë©´ 0.0)
        row = []
        for col in col_order:
            if col == "Overall":
                v = float(similarity)
            else:   
                v = float(details.get(key_map[col], 0.0))
            row.append(v)

        rows.append(row)
        # í–‰ ë¼ë²¨: íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        index_labels.append(p.stem)

    # DataFrame êµ¬ì„±(ì œëª© ì—´ì„ ë§¨ ì•ì— ì¶”ê°€)
    df = pd.DataFrame(rows, index=index_labels, columns=col_order)
    df.insert(0, title, index_labels)

    # í‰ê·  í–‰ ì¶”ê°€(ì œëª© ì¹¸ì€ 'AVG')
    if len(df) > 0:
        avg_vals = df[col_order].mean(axis=0).to_list()
        avg_row = pd.DataFrame([[ "AVG", *avg_vals ]], columns=[title, *col_order])
        df = pd.concat([df, avg_row], ignore_index=True)

    # ì €ì¥
    try:
        df.to_csv(output_csv_path, index=False, encoding="utf-8-sig")
        print(f"[ì™„ë£Œ] ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {output_csv_path}")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] CSV ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")

    return df


# =============================== Main ==============================

if __name__ == "__main__":
    print("ë³µì‹± ë™ì‘ DTW ë¶„ì„ê¸° (v2.14 - ì•ˆì •ì„±/ì •í™•ë„ ê°•í™”)")
    print("=" * 64)

    # uppercut_left_001.csv
    # uppercut_right_002.csv
    # hook_left_002.csv
    # hook_right_001.csv
    # jap_001.csv
    # straight_003.csv

    #file1 = "/Users/jonabi/Downloads/TEPA/mocap_test/uppercut_right_004.csv"
    #file2 = "/Users/jonabi/Downloads/TEPA/p24_Global"
    
    # ìœˆë„ìš° ê¸°ì¤€ 
    file1 = "C:\\Users\\PC\\Documents\\GitHub\\Collaborate_Code\\mocap_test\\uppercut_left_001.csv"
    file2 = "C:\\Users\\PC\\Documents\\GitHub\\Collaborate_Code\\p24_Global"
 
    #file1 = "C:\\Users\\user\\Downloads\\TEPA\\Collaborate_Code\\mocap_test\\jap_005.csv"
    #file2 = "C:\\Users\\user\\Downloads\\TEPA\\Collaborate_Code\\p26_Global"
 
    # ì‹¤í–‰ ì¤‘ ì–´ë–¤ íŒŒì¼ì„ ë¹„êµí•˜ëŠ”ì§€ í‘œì‹œ
    # print(f"ë¶„ì„ ëŒ€ìƒ íŒŒì¼ 1: {file1}")
    # print(f"ë¶„ì„ ëŒ€ìƒ íŒŒì¼ 2: {file2}")
 
    # ê°€ì¤‘ì¹˜ ì‚¬ìš©ì ì •ì˜ ì˜ˆì‹œ (í•„ìš” ì‹œ ìˆ˜ì •)
    custom_feature_weights = {
        'position': 0.0,
        'rotation': 0.7,
        'velocity': 0.0,
        'acceleration': 0.0,
        'joint_angles': 0.3,
    }

    analyzer = MocapMotionAnalyzer(scaling='standard', feature_weights=custom_feature_weights)  
    
    ### ====> ì¶”ê°€í•œ ë¶€ë¶„.
    
    # ğŸ‘‰ ë°°ì¹˜ ë¹„êµ ì‹¤í–‰ (ì¶œë ¥ë§Œ)
    #  - keyword: íŠ¹ì • ë‹¨ì–´ê°€ íŒŒì¼ëª…ì— í¬í•¨ëœ ê²ƒë§Œ ë¹„êµí•˜ê³  ì‹¶ìœ¼ë©´ ë„£ê¸° (ì˜ˆ: "post" ë˜ëŠ” "hook_left")
    #  - limit: ìƒìœ„ Nê°œë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ìœ¼ë©´ ìˆ«ì ì§€ì •
    # print_similarity_batch(
    #     file1_path=file1,
    #     file2_dir=file2,
    #     analyzer=analyzer,
    #     keyword="uppercut_left",   # ì˜ˆ: "post" ë˜ëŠ” None
    #     limit=None      # ì˜ˆ: 10 ë˜ëŠ” None
    # )
    
    _ = save_similarity_matrix(
        file1_path=file1,
        file2_dir=file2,
        analyzer=analyzer,
        keyword="uppercut_right",      # í•„ìš” ì‹œ ìˆ˜ì •
        limit=None,                   # í•„ìš” ì‹œ ìˆ«ì
        title="uppercut_left",          # ì‹œíŠ¸ ì¢Œì¸¡ ì²« ì—´ ì œëª©
        output_csv_path="p23_uppercut_left_004_similarity_matrix.csv"      # ì‹œíŠ¸ ì¢Œì¸¡ ì²« ì—´ ì œëª©
    )
    
    # 'standard' | 'minmax' | None
    # motion1 = analyzer.load_mocap_data(file1)
    # motion2 = analyzer.load_mocap_data(file2)
    # if motion1 is not None and motion2 is not None:
    #     similarity, details = analyzer.compare_motions(motion1, motion2)
    #     analyzer.visualize_results(similarity, details)
    #     analyzer.animate_3d_segments(motion1, motion2, save_path="output.gif")
    # else:
    #     print("íŒŒì¼ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")