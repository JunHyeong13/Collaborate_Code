import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from typing import Dict, List, Optional
import warnings

# dtaidistance ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from dtaidistance import dtw
from dtaidistance import dtw_visualisation as dtwvis

warnings.filterwarnings('ignore')

class PoseSimilarityAnalyzer:
    """
    ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ í¬ì¦ˆ ì‹œí€€ìŠ¤ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤.
    - ì£¼ìš” ê¸°ëŠ¥: DTW, í”„ë ˆì„ë³„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ê´€ì ˆë³„ ì°¨ì´ ë¶„ì„, í”¼ë“œë°± ìƒì„±, ì‹œê°í™”.
    - ê°œì„  ì‚¬í•­: dtaidistance ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ, ì‹œê°„ì  íŠ¹ì„±ì„ ê³ ë ¤í•œ ì •í™•í•œ ìœ ì‚¬ë„ ê³„ì‚°.
    """
    def __init__(self):
        self.trainer_data: Optional[pd.DataFrame] = None
        self.member_data: Optional[pd.DataFrame] = None
        self.joint_names = [
            'Hip', 'Ab', 'Chest', 'Neck', 'Head', 'LShoulder', 'LUArm', 'LFArm', 'LHand',
            'RShoulder', 'RUArm', 'RFArm', 'RHand', 'LThigh', 'LShin', 'LFoot',
            'RThigh', 'RShin', 'RFoot', 'LToe', 'RToe'
        ]
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë‚´ë¶€ ë³€ìˆ˜
        self.analysis_results = {}

    def load_data(self, trainer_csv: str, member_csv: str) -> None:
        """íŠ¸ë ˆì´ë„ˆì™€ íšŒì› ë°ì´í„° ë¡œë“œ"""
        try:
            self.trainer_data = pd.read_csv(trainer_csv).rename(columns=str.strip)
            self.member_data = pd.read_csv(member_csv).rename(columns=str.strip)
            print(f"âœ… íŠ¸ë ˆì´ë„ˆ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {os.path.basename(trainer_csv)} ({len(self.trainer_data)} í”„ë ˆì„)")
            print(f"âœ… íšŒì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {os.path.basename(member_csv)} ({len(self.member_data)} í”„ë ˆì„)")
        except FileNotFoundError as e:
            raise FileNotFoundError(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n{e}")
        except Exception as e:
            raise IOError(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def _preprocess_and_weight(self, data: pd.DataFrame, feature_cols: List[str], joint_weights: Optional[Dict[str, float]] = None) -> np.ndarray:
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ê´€ì ˆ ê°€ì¤‘ì¹˜ ì ìš©"""
        data_filled = data.fillna(method='ffill').fillna(method='bfill')
        features_df = data_filled[feature_cols]

        if joint_weights is None:
            joint_weights = self._get_default_weights()

        weighted_features_list = []
        for col in features_df.columns:
            weight = 1.0
            for joint, w in joint_weights.items():
                if col.startswith(joint + '.'):
                    weight = w
                    break
            weighted_features_list.append(features_df[col] * weight)

        return np.column_stack(weighted_features_list)

    def _get_default_weights(self) -> Dict[str, float]:
        """ê¸°ë³¸ ê´€ì ˆ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        return {
            'Hip': 1.5, 'Ab': 1.3, 'Chest': 1.2, 'LThigh': 1.4, 'RThigh': 1.4,
            'LShin': 1.2, 'RShin': 1.2, 'LFoot': 1.0, 'RFoot': 1.0,
            'LShoulder': 1.1, 'RShoulder': 1.1, 'LUArm': 1.0, 'RUArm': 1.0,
        }

    def analyze(self) -> None:
        """ëª¨ë“  ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‚´ë¶€ì— ì €ì¥"""
        if self.trainer_data is None or self.member_data is None:
            raise ValueError("ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

        # --- BUG FIX: ë‘ ë°ì´í„°ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” featureë§Œ ì„ íƒ ---
        trainer_cols = self.trainer_data.select_dtypes(include=np.number).columns
        member_cols = self.member_data.select_dtypes(include=np.number).columns
        common_cols = list(set(trainer_cols) & set(member_cols))
        feature_cols = [col for col in common_cols if col not in ['Frame', 'Time (Seconds)']]
        
        if not feature_cols:
            raise ValueError("ë‘ ë°ì´í„° íŒŒì¼ì— ê³µí†µëœ íŠ¹ì§•(feature) ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # --- 1. ì „ì²´ ë™ì‘ ìœ ì‚¬ë„ ë¶„ì„ ---
        trainer_weighted = self._preprocess_and_weight(self.trainer_data, feature_cols)
        member_weighted = self._preprocess_and_weight(self.member_data, feature_cols)

        scaler = StandardScaler()
        combined_data = np.vstack([trainer_weighted, member_weighted])
        scaler.fit(combined_data)

        trainer_scaled = scaler.transform(trainer_weighted)
        member_scaled = scaler.transform(member_weighted)

        dtw_dist = dtw.distance(trainer_scaled, member_scaled, use_pruning=True)
        normalized_dtw_dist = dtw_dist / (len(trainer_scaled) + len(member_scaled))

        min_len = min(len(trainer_scaled), len(member_scaled))
        frame_cos_sim = [
            cosine_similarity(trainer_scaled[i].reshape(1, -1), member_scaled[i].reshape(1, -1))[0, 0]
            for i in range(min_len)
        ]
        avg_cos_sim = np.mean(frame_cos_sim) if frame_cos_sim else 0

        self.analysis_results['DTW_Similarity'] = max(0, 100 - normalized_dtw_dist * 25)
        self.analysis_results['Cosine_Similarity'] = avg_cos_sim * 100
        self.analysis_results['Overall_Score'] = (
            self.analysis_results['DTW_Similarity'] * 0.7 +
            self.analysis_results['Cosine_Similarity'] * 0.3
        )

        # --- 2. ê´€ì ˆë³„ ì›€ì§ì„ ì°¨ì´ ë¶„ì„ ---
        joint_scores = {}
        for joint in self.joint_names:
            joint_cols = [col for col in feature_cols if col.startswith(joint + '.')]
            if not joint_cols:
                continue

            trainer_joint_seq = self.trainer_data[joint_cols].values
            member_joint_seq = self.member_data[joint_cols].values

            if trainer_joint_seq.shape[0] == 0 or member_joint_seq.shape[0] == 0:
                continue

            scaler_joint = StandardScaler()
            combined_joint_seq = np.vstack([trainer_joint_seq, member_joint_seq])
            scaler_joint.fit(combined_joint_seq)

            trainer_joint_scaled = scaler_joint.transform(trainer_joint_seq)
            member_joint_scaled = scaler_joint.transform(member_joint_seq)

            j_dist = dtw.distance(trainer_joint_scaled, member_joint_scaled, use_pruning=True)
            j_dist_norm = j_dist / (len(trainer_joint_scaled) + len(member_joint_scaled))
            joint_scores[joint] = max(0, 100 - j_dist_norm * 50)

        self.analysis_results['Joint_Scores'] = joint_scores
        self.analysis_results['scaled_data'] = (trainer_scaled, member_scaled)

    def get_feedback(self) -> str:
        """ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜í•œ í…ìŠ¤íŠ¸ í”¼ë“œë°± ìƒì„±"""
        if not self.analysis_results:
            return "ë¶„ì„ì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
            
        overall = self.analysis_results.get('Overall_Score', 0)
        joint_scores = self.analysis_results.get('Joint_Scores', {})
        
        feedback = []
        if overall >= 90:
            feedback.append("ğŸ† í›Œë¥­í•©ë‹ˆë‹¤! íŠ¸ë ˆì´ë„ˆì™€ ê±°ì˜ ì¼ì¹˜í•˜ëŠ” ì™„ë²½í•œ ìì„¸ì…ë‹ˆë‹¤.")
        elif overall >= 80:
            feedback.append("ğŸ‘ ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ë” ê°œì„ í•˜ë©´ ì™„ë²½í•´ì§‘ë‹ˆë‹¤.")
        elif overall >= 70:
            feedback.append("âœ… ì–‘í˜¸í•œ ìì„¸ì…ë‹ˆë‹¤. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
        else:
            feedback.append("ğŸ”´ ìì„¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ë„ˆì˜ ë™ì‘ê³¼ ì°¨ì´ê°€ í° ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.")
        
        if joint_scores:
            worst_joints = sorted(joint_scores.items(), key=lambda x: x[1])[:3]
            if worst_joints and worst_joints[0][1] < 85:
                feedback.append("\nğŸ“ íŠ¹íˆ ë‹¤ìŒ ë¶€ìœ„ì˜ 'ì›€ì§ì„' ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤:")
                for joint, score in worst_joints:
                    if score < 85:
                        feedback.append(f"  - {joint} (ìœ ì‚¬ë„: {score:.1f}%)")
        
        return "\n".join(feedback)
        
    def display_results(self):
        """ì½˜ì†”ì— ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*25)
        print("ğŸ“ˆ  ìœ ì‚¬ë„ ë¶„ì„ ì¢…í•© ê²°ê³¼")
        print("="*25)
        for key, val in self.analysis_results.items():
            if key not in ['Joint_Scores', 'scaled_data']:
                print(f"{key:<20}: {val:.2f}")
        
        print("\n" + "="*25)
        print("ğŸ¤¸ ê´€ì ˆë³„ ì›€ì§ì„ ìœ ì‚¬ë„")
        print("="*25)
        joint_scores = self.analysis_results.get('Joint_Scores', {})
        if joint_scores:
            for joint, score in sorted(joint_scores.items(), key=lambda x: x[1]):
                status = "ğŸŸ¢" if score >= 85 else "ğŸŸ¡" if score >= 70 else "ğŸ”´"
                print(f"{status} {joint:<12}: {score:.1f}%")

    def visualize_analysis(self, save_plot: bool = False):
        """ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        # (ì‹œê°í™” ì½”ë“œëŠ” ë³€ê²½ì‚¬í•­ì´ ì—†ìœ¼ë¯€ë¡œ ìƒëµ - ì´ì „ ë‹µë³€ì˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        """ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        if not self.analysis_results:
            print("ë¶„ì„ì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
            return

        plt.style.use('seaborn-v0_8-whitegrid')
        fig = plt.figure(figsize=(18, 16))
        
        # 1. ì¢…í•© ì ìˆ˜
        ax1 = plt.subplot2grid((3, 2), (0, 0))
        metrics = ['DTW_Similarity', 'Cosine_Similarity', 'Overall_Score']
        values = [self.analysis_results.get(m, 0) for m in metrics]
        colors = ['skyblue', 'lightgreen', 'gold']
        bars = ax1.bar(metrics, values, color=colors, alpha=0.8)
        ax1.set_title('Overall Similarity Scores', fontsize=16)
        ax1.set_ylabel('Score (0-100)', fontsize=12)
        ax1.set_ylim(0, 105)
        for bar in bars:
            yval = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.1f}', va='bottom', ha='center')

        # 2. ê´€ì ˆë³„ ìœ ì‚¬ë„
        ax2 = plt.subplot2grid((3, 2), (0, 1))
        joint_scores = self.analysis_results.get('Joint_Scores', {})
        if joint_scores:
            sorted_joints = sorted(joint_scores.items(), key=lambda x: x[1])
            joints = [j[0] for j in sorted_joints]
            scores = [j[1] for j in sorted_joints]
            colors = ['#d9534f' if s < 70 else '#f0ad4e' if s < 85 else '#5cb85c' for s in scores]
            ax2.barh(joints, scores, color=colors)
            ax2.set_title('Joint Movement Similarity', fontsize=16)
            ax2.set_xlabel('Similarity Score (%)', fontsize=12)
            ax2.axvline(x=85, color='gray', linestyle='--', alpha=0.7)

        # 3. ëŒ€í‘œ ê´€ì ˆ ì‹œê³„ì—´ ë¹„êµ (Hip.posY)
        ax3 = plt.subplot2grid((3, 2), (1, 0), colspan=2)
        if 'Time (Seconds)' in self.trainer_data.columns and 'Hip.posY' in self.trainer_data.columns:
            ax3.plot(self.trainer_data['Time (Seconds)'], self.trainer_data['Hip.posY'], label='Trainer', lw=2)
            ax3.plot(self.member_data['Time (Seconds)'], self.member_data['Hip.posY'], label='Member', lw=2, alpha=0.8)
            ax3.set_title('Hip Y-Position Trajectory', fontsize=16)
            ax3.set_xlabel('Time (s)', fontsize=12)
            ax3.set_ylabel('Position', fontsize=12)
            ax3.legend()

        # 4. DTW ì‹œê°„ ì™œê³¡ ê²½ë¡œ ì‹œê°í™” (ê°œì„ ëœ ì‹œê°í™”)
        ax4 = plt.subplot2grid((3, 2), (2, 0), colspan=2)
        trainer_s, member_s = self.analysis_results.get('scaled_data', (None, None))
        if trainer_s is not None and member_s is not None:
            path = dtw.warping_path(trainer_s, member_s)
            dtwvis.plot_warping(trainer_s, member_s, path, ax=ax4)
            ax4.set_title('DTW Warping Path (Time Alignment)', fontsize=16)
            ax4.set_xlabel("Trainer's Frames", fontsize=12)
            ax4.set_ylabel("Member's Frames", fontsize=12)

        plt.tight_layout(pad=3.0)
        if save_plot:
            plt.savefig('pose_similarity_analysis.png', dpi=300)
            print("\nğŸ–¼ï¸  'pose_similarity_analysis.png' íŒŒì¼ë¡œ ì‹œê°í™” ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        plt.show()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # --- test í´ë”ì˜ ì‹¤ì œ CSV ì‚¬ìš© ---
    base = os.path.join(os.path.dirname(__file__), 'test')
    trainer_file = os.path.join(base, 'jap_001.csv')
    member_file = os.path.join(base, 'p04_jap_main_013.csv')
    if not (os.path.isfile(trainer_file) and os.path.isfile(member_file)):
        print("âŒ test í´ë”ì—ì„œ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:")
        print(f"  trainer_file: {trainer_file}")
        print(f"  member_file : {member_file}")
        return
    
    # --- ë¶„ì„ê¸° ì‹¤í–‰ ---
    analyzer = PoseSimilarityAnalyzer()
    
    try:
        analyzer.load_data(trainer_file, member_file)
        
        # ëª¨ë“  ë¶„ì„ ìˆ˜í–‰
        analyzer.analyze()
        
        # ê²°ê³¼ ì¶œë ¥
        analyzer.display_results()
        
        # í”¼ë“œë°± ì¶œë ¥
        print("\n" + "="*25)
        print("ğŸ“ ê°œì„  í”¼ë“œë°±")
        print("="*25)
        print(analyzer.get_feedback())

        # ì‹œê°í™”
        analyzer.visualize_analysis(save_plot=True)

    except (FileNotFoundError, ValueError, IOError) as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()